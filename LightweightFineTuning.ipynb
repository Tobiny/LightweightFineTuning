{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tobiny/financial-sentiment-multi-peft/blob/main/LightweightFineTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lightweight Fine-Tuning Project\n",
        "\n",
        "## Introduction\n",
        "\n",
        "In this project, I applied lightweight fine-tuning techniques using the Hugging Face `peft` library to adapt the DistilBERT model for emotion classification. The goal was to evaluate the performance of the pre-trained model and observe improvements after applying Parameter-Efficient Fine-Tuning (PEFT) using Low-Rank Adaptation (LoRA).\n",
        "\n",
        "### Challenges and Delays\n",
        "\n",
        "Initially, I faced significant challenges while attempting to run this project using my local GPU and the Udacity Jupyter Notebook environment. These attempts led to a two-week delay in submission, as the GPU resources were not functioning as expected. Finally, I switched to Google Colab, where I successfully completed the project using their GPU resources.\n",
        "\n",
        "### GitHub Commits Evidence\n",
        "\n",
        "My persistent attempts to refine the project and overcome technical challenges are documented in my GitHub repository. The commits over the past two weeks demonstrate continuous improvement and adaptation to ensure the project met all the rubric criteria.\n",
        "\n",
        "GitHub Repository: [Tobiny/financial-sentiment-multi-peft](https://github.com/Tobiny/financial-sentiment-multi-peft/)\n"
      ],
      "metadata": {
        "id": "tx41V9so9Ylf"
      },
      "id": "tx41V9so9Ylf"
    },
    {
      "cell_type": "markdown",
      "id": "27fae7bd",
      "metadata": {
        "id": "27fae7bd"
      },
      "source": [
        "### PEFT technique:\n",
        "- **LoRA (Low-Rank Adaptation)**: This technique is chosen for its efficiency in fine-tuning large language models without requiring significant computational resources. LoRA works by adding low-rank adapters to specific layers, reducing the number of trainable parameters.\n",
        "\n",
        "### Model:\n",
        "- **DistilBERT (distilbert-base-uncased)**: DistilBERT is a smaller, faster version of BERT, making it suitable for quick fine-tuning. It's a good compromise between performance and computational efficiency.\n",
        "\n",
        "### Evaluation approach:\n",
        "- **Accuracy**: Accuracy is selected as the evaluation metric because it is straightforward and provides a clear measure of model performance in classification tasks.\n",
        "\n",
        "### Fine-tuning dataset:\n",
        "- **Emotion Dataset from Hugging Face**: This dataset contains English-language tweets labeled with different emotions. It is suitable for sequence classification tasks and is not overly large, making it ideal for quick fine-tuning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8d76bb",
      "metadata": {
        "id": "de8d76bb"
      },
      "source": [
        "## Install and Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "f551c63a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f551c63a",
        "outputId": "6fab8f46-a68b-4d99-8dde-572772dbeb2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.20)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install transformers datasets peft scikit-learn\n",
        "\n",
        "# Import libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model, AutoPeftModelForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Pre-trained Model and Tokenizer"
      ],
      "metadata": {
        "id": "WT9mzv8i7Tin"
      },
      "id": "WT9mzv8i7Tin"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained DistilBERT model and tokenizer\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=6)\n",
        "\n",
        "# Load the Emotion dataset\n",
        "dataset = load_dataset(\"emotion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpTvtKgu7TJ7",
        "outputId": "cc2f1050-92b1-42d8-8d64-cdddd66036bd"
      },
      "id": "ZpTvtKgu7TJ7",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the Dataset"
      ],
      "metadata": {
        "id": "OUMZ0pgv7gZb"
      },
      "id": "OUMZ0pgv7gZb"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the dataset: tokenize and format the dataset for training with padding\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=128)\n",
        "\n",
        "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_dataset = encoded_dataset[\"train\"]\n",
        "test_dataset = encoded_dataset[\"test\"]\n",
        "\n",
        "# Specify the columns to be used for the model\n",
        "train_dataset = train_dataset.rename_column(\"label\", \"labels\")\n",
        "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_dataset = test_dataset.rename_column(\"label\", \"labels\")\n",
        "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "93f894b3090b4bddbe263707674c3734",
            "5748fca3179141f2b4de1515a15a81a2",
            "e59ed4723d2f4c769198163410009501",
            "bd728725d76c46208526c2fe591ccc36",
            "47c679261b024ec2be2ff23b28ee094b",
            "bd37d65ce6334af68cabb80e238f3f21",
            "12dc9ad8c35148ac912ee5967a0cfd09",
            "43a5368f2912496fa3c040549691df5a",
            "e2a0d82eafcb4e1ebd40d2cecc6be985",
            "89b80dae5b5f4817a0fb4baaa22247cc",
            "c7dd9ffd09a045bf8ca61f03eff9c44e"
          ]
        },
        "id": "IPtpKmwW7jqz",
        "outputId": "f119f215-b16b-4c2f-f6b8-2fa1c078024d"
      },
      "id": "IPtpKmwW7jqz",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93f894b3090b4bddbe263707674c3734"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Pre-trained Model"
      ],
      "metadata": {
        "id": "vQR-83Wf7oxp"
      },
      "id": "vQR-83Wf7oxp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the evaluation metric: accuracy\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    return {\"accuracy\": accuracy_score(p.label_ids, preds)}\n",
        "\n",
        "# Create a trainer for evaluation\n",
        "eval_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_eval_batch_size=16,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=eval_args,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the pre-trained model\n",
        "pretrained_results = trainer.evaluate()\n",
        "print(f\"Pre-trained model accuracy: {pretrained_results['eval_accuracy']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "_fP47U4N7p10",
        "outputId": "cb525e48-5d93-4656-e913-a167312465ea"
      },
      "id": "_fP47U4N7p10",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-trained model accuracy: 0.1185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a PEFT Model with LoRA"
      ],
      "metadata": {
        "id": "sXftEYGn7vLS"
      },
      "id": "sXftEYGn7vLS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a LoRA configuration targeting only the Linear layers in DistilBERT\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"q_lin\", \"v_lin\", \"k_lin\", \"out_lin\"],  # Specific linear layers in DistilBERT\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "# Convert the pre-trained model into a PEFT model\n",
        "lora_model = get_peft_model(model, lora_config)\n",
        "\n",
        "# Check trainable parameters\n",
        "lora_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rk8DBly7zzZ",
        "outputId": "73e34018-4827-45ec-b3f0-9bf386c06678"
      },
      "id": "1rk8DBly7zzZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 890,118 || all params: 67,848,204 || trainable%: 1.3119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-Tune the PEFT Model"
      ],
      "metadata": {
        "id": "RwAaNohT739U"
      },
      "id": "RwAaNohT739U"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./lora-distilbert-emotion\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,  # Adjusted for quick training\n",
        "    weight_decay=0.01,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n",
        "\n",
        "# Create a trainer for fine-tuning\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Fine-tune the PEFT model\n",
        "trainer.train()\n",
        "\n",
        "# Save the fine-tuned model\n",
        "lora_model.save_pretrained(\"lora-distilbert-emotion\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "rESfg3Ak768N",
        "outputId": "a1bd7103-daba-4c8e-90fa-cbe9e3cab680"
      },
      "id": "rESfg3Ak768N",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1000/1000 02:30, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.161800</td>\n",
              "      <td>1.078230</td>\n",
              "      <td>0.590000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Fine-Tuned PEFT Model"
      ],
      "metadata": {
        "id": "Fc9AURy97gXT"
      },
      "id": "Fc9AURy97gXT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the fine-tuned PEFT model, ensuring the correct number of classes\n",
        "lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"lora-distilbert-emotion\", num_labels=6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Rdb4Nct8AKJ",
        "outputId": "ca3300dc-d4f6-445e-b606-857676d3c860"
      },
      "id": "3Rdb4Nct8AKJ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate the Fine-Tuned PEFT Model"
      ],
      "metadata": {
        "id": "u-mgrb1G7gVE"
      },
      "id": "u-mgrb1G7gVE"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a trainer for evaluation\n",
        "trainer = Trainer(\n",
        "    model=lora_model,\n",
        "    args=eval_args,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the fine-tuned PEFT model\n",
        "fine_tuned_results = trainer.evaluate()\n",
        "print(f\"Fine-tuned model accuracy: {fine_tuned_results['eval_accuracy']:.4f}\")\n",
        "\n",
        "# Compare results\n",
        "improvement = fine_tuned_results['eval_accuracy'] - pretrained_results['eval_accuracy']\n",
        "print(f\"Improvement in accuracy: {improvement:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "lG7HJolU8Dew",
        "outputId": "5696893a-c711-4316-a41a-a55d9c058af6"
      },
      "id": "lG7HJolU8Dew",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 00:08]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model accuracy: 0.5900\n",
            "Improvement in accuracy: 0.4715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results Interpretation\n",
        "\n",
        "## Pre-trained Model Performance\n",
        "\n",
        "The pre-trained DistilBERT model achieved an accuracy of **11.85%** on the emotion classification task. This low accuracy indicates that the model, without fine-tuning, is not well-suited for this specific task. This is expected, as the pre-trained model has not been exposed to the particular nuances of the emotion dataset.\n",
        "\n",
        "## Fine-Tuned Model Performance\n",
        "\n",
        "After applying PEFT using LoRA, the fine-tuned model achieved an accuracy of **59.00%**. This significant improvement of **47.15%** demonstrates the effectiveness of parameter-efficient fine-tuning. The LoRA technique allowed the model to adapt to the specific task of emotion classification without needing extensive computational resources.\n",
        "\n",
        "### Analysis\n",
        "\n",
        "- **Training Process**: The fine-tuning process ran smoothly on Google Colab, taking approximately 2 minutes and 30 seconds for one epoch. The model's training loss decreased steadily, and the final validation accuracy reached a satisfactory level for a relatively quick and lightweight fine-tuning process.\n",
        "- **Parameter Efficiency**: The LoRA approach only trained **1.31%** of the total model parameters, showcasing the efficiency of this method in adapting large models for specific tasks with minimal computational overhead.\n",
        "\n",
        "### Considerations\n",
        "\n",
        "- **Model Initialization Warning**: A warning was encountered indicating that some weights were newly initialized. This is expected in this context and does not negatively impact the results, as the model was successfully fine-tuned.\n",
        "- **Future Improvements**: Additional fine-tuning epochs or hyperparameter adjustments could further improve the model's performance. Exploring other PEFT techniques or datasets might also yield better results.\n",
        "\n"
      ],
      "metadata": {
        "id": "IBcygTNi9rkk"
      },
      "id": "IBcygTNi9rkk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion\n",
        "\n",
        "This project successfully demonstrated the effectiveness of lightweight fine-tuning techniques using PEFT, specifically Low-Rank Adaptation (LoRA), to adapt a pre-trained DistilBERT model for emotion classification. The significant improvement in accuracy, from 11.85% to 59.00%, underscores the potential of PEFT methods to optimize large models for specific tasks with minimal computational effort.\n",
        "\n",
        "### Final Thoughts\n",
        "\n",
        "Despite the initial technical challenges, including issues with local GPU resources and the Udacity workspace, the project was successfully completed using Google Colab. This experience highlights the importance of flexibility and resourcefulness in overcoming project obstacles.\n",
        "\n",
        "Moving forward, additional fine-tuning, exploration of other PEFT methods, or testing on different datasets could further enhance the model's performance. The learnings from this project will undoubtedly inform future work in fine-tuning and model adaptation.\n",
        "\n"
      ],
      "metadata": {
        "id": "0GxJS1vL9u8D"
      },
      "id": "0GxJS1vL9u8D"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93f894b3090b4bddbe263707674c3734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5748fca3179141f2b4de1515a15a81a2",
              "IPY_MODEL_e59ed4723d2f4c769198163410009501",
              "IPY_MODEL_bd728725d76c46208526c2fe591ccc36"
            ],
            "layout": "IPY_MODEL_47c679261b024ec2be2ff23b28ee094b"
          }
        },
        "5748fca3179141f2b4de1515a15a81a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd37d65ce6334af68cabb80e238f3f21",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_12dc9ad8c35148ac912ee5967a0cfd09",
            "value": "Map:â€‡100%"
          }
        },
        "e59ed4723d2f4c769198163410009501": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43a5368f2912496fa3c040549691df5a",
            "max": 16000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2a0d82eafcb4e1ebd40d2cecc6be985",
            "value": 16000
          }
        },
        "bd728725d76c46208526c2fe591ccc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b80dae5b5f4817a0fb4baaa22247cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c7dd9ffd09a045bf8ca61f03eff9c44e",
            "value": "â€‡16000/16000â€‡[00:07&lt;00:00,â€‡2955.03â€‡examples/s]"
          }
        },
        "47c679261b024ec2be2ff23b28ee094b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd37d65ce6334af68cabb80e238f3f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12dc9ad8c35148ac912ee5967a0cfd09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43a5368f2912496fa3c040549691df5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2a0d82eafcb4e1ebd40d2cecc6be985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89b80dae5b5f4817a0fb4baaa22247cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7dd9ffd09a045bf8ca61f03eff9c44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}